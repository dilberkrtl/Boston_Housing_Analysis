{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pandas library to read the dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Reading the Boston housing dataset from a CSV file. The file path is provided.\n",
    "boston = pd.read_csv(r\"C:\\Users\\MSI-NB\\Desktop\\Machine_Learning_Projects\\Boston_Housing_Analysis\\boston.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 16 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   TOWN     506 non-null    object \n",
      " 1   TRACT    506 non-null    int64  \n",
      " 2   LON      506 non-null    float64\n",
      " 3   LAT      506 non-null    float64\n",
      " 4   MEDV     506 non-null    float64\n",
      " 5   CRIM     506 non-null    float64\n",
      " 6   ZN       506 non-null    float64\n",
      " 7   INDUS    506 non-null    float64\n",
      " 8   CHAS     506 non-null    int64  \n",
      " 9   NOX      506 non-null    float64\n",
      " 10  RM       506 non-null    float64\n",
      " 11  AGE      506 non-null    float64\n",
      " 12  DIS      506 non-null    float64\n",
      " 13  RAD      506 non-null    int64  \n",
      " 14  TAX      506 non-null    int64  \n",
      " 15  PTRATIO  506 non-null    float64\n",
      "dtypes: float64(11), int64(4), object(1)\n",
      "memory usage: 63.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Displaying general information about the dataset (data types, missing values, etc.)\n",
    "boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing mglearn library which provides datasets and tools for visualization\n",
    "import mglearn\n",
    "import mglearn.datasets\n",
    "\n",
    "# Loading the extended Boston dataset using mglearn. This dataset has more features than the standard Boston dataset.\n",
    "x, y = mglearn.datasets.load_extended_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 104)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing train_test_split from sklearn.model_selection to split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into training and testing sets with a fixed random_state for reproducibility\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RIDGE LEGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **RIDGE REGRESSION**: Using L2 regularization for linear regression.\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Using default alpha = 1.0, which is a moderate level of regularization.\n",
    "# The model might overfit the data (especially if there are many features), leading to high training accuracy and low test accuracy.\n",
    "ridge = Ridge().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.885796658517094\n",
      "0.752768348174475\n"
     ]
    }
   ],
   "source": [
    "# Print model's accuracy on training and test sets\n",
    "print(ridge.score(x_train, y_train))  # High training score could indicate overfitting\n",
    "print(ridge.score(x_test, y_test))  # Low test score indicates overfitting on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7882787115369614\n",
      "0.6359411489177309\n"
     ]
    }
   ],
   "source": [
    "# Trying with a larger alpha = 10 to apply stronger regularization.\n",
    "# The model becomes simpler and less likely to overfit, but it might underfit if the regularization is too strong.\n",
    "ridge10 = Ridge(alpha=10).fit(x_train, y_train)\n",
    "\n",
    "# Print the accuracy scores for the new model\n",
    "print(ridge10.score(x_train, y_train))  # Possibly lower training accuracy, reduced overfitting\n",
    "print(ridge10.score(x_test, y_test))  # Test accuracy might improve, or could still be low if underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9282273685001988\n",
      "0.7722067936479631\n"
     ]
    }
   ],
   "source": [
    "# Trying with a smaller alpha = 0.1 to reduce regularization slightly.\n",
    "# The model could start fitting the data better, but might still overfit to the training data.\n",
    "ridge01 = Ridge(alpha=0.1).fit(x_train, y_train)\n",
    "\n",
    "# Print accuracy scores\n",
    "print(ridge01.score(x_train, y_train))  # Possible higher training accuracy, indicating less regularization\n",
    "print(ridge01.score(x_test, y_test))  # Better balance between training and test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LASSO LEGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **LASSO REGRESSION**: Using L1 regularization for linear regression, which can drive some coefficients to zero.\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Lasso regression model with default alpha = 1.0.\n",
    "# Similar to Ridge, Lasso also applies regularization but has the added benefit of setting some coefficients to zero.\n",
    "lasso = Lasso().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29323768991114607\n",
      "0.20937503255272294\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy scores\n",
    "print(lasso.score(x_train, y_train))  # High training accuracy might indicate overfitting\n",
    "print(lasso.score(x_test, y_test))  # Low test accuracy suggests overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sum(lasso.coef_!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8962226511086497\n",
      "0.7656571174549982\n"
     ]
    }
   ],
   "source": [
    "# Using a smaller alpha = 0.01 to reduce regularization, allowing the model to become more complex.\n",
    "lasso001 = Lasso(alpha=0.01, max_iter=100000).fit(x_train, y_train)\n",
    "\n",
    "# Print accuracy scores\n",
    "print(lasso001.score(x_train, y_train))  # Possible overfitting, the model fits training data closely\n",
    "print(lasso001.score(x_test, y_test))  # Check if overfitting still occurs on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9507158754515463\n",
      "0.6437467421272821\n"
     ]
    }
   ],
   "source": [
    "# Using an even smaller alpha = 0.0001 to reduce regularization further.\n",
    "# This will allow the model to fit even closer to the data, which can lead to overfitting.\n",
    "lasso00001 = Lasso(alpha=0.0001, max_iter=100000).fit(x_train, y_train)\n",
    "\n",
    "# Print accuracy scores\n",
    "print(lasso00001.score(x_train, y_train))  # High training accuracy\n",
    "print(lasso00001.score(x_test, y_test))  # Check for overfitting or underfitting on the test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
